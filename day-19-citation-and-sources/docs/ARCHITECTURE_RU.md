# Архитектура системы индексации документов

Этот документ описывает внутреннюю архитектуру и процесс работы системы индексации документов, включая разбиение на чанки, векторизацию и семантический поиск.

## Обзор процесса

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  Документы  │ -> │  Чанкинг    │ -> │ Векторизация│ -> │   SQLite    │
│  (.md, .txt)│    │  (TextChunker)  │    │  (Ollama)   │    │   (хранение)│
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
                                                               │
                                                               v
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  Результаты │ <- │  Ранжирование│ <- │ Сравнение   │ <- │   Запрос    │
│             │    │  (Top-K)    │    │  (cosine)   │    │  (embedding)│
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

## 1. Разбиение на чанки (Chunking)

### Зачем нужно разбиение?

Языковые модели для генерации эмбеддингов имеют ограничения на длину входного текста. Кроме того, для точного семантического поиска важно, чтобы каждый чанк содержал целостную смысловую единицу.

### Стратегии разбиения

Система поддерживает три стратегии (`ChunkStrategy`):

#### 1.1 По символам (BY_CHARACTERS) — по умолчанию

```kotlin
chunkSize = 500      // размер чанка в символах
overlapSize = 50     // перекрытие между чанками
```

**Принцип работы:**
- Текст делится на фрагменты по 500 символов
- Каждый следующий чанк начинается с отступом 450 символов (500 - 50)
- Перекрытие обеспечивает, что смысл на границах чанков не теряется

**Пример:**
```
Исходный текст (1000 символов):
[0-500] -> Чанк 1
[450-950] -> Чанк 2  (перекрытие 50 символов с чанком 1)
[900-1000] -> Чанк 3
```

#### 1.2 По токенам (BY_TOKENS)

Использует приблизительное соотношение: **1 токен ≈ 4 символа** (для английского текста).

```kotlin
chunkSize = 125      // ~500 символов / 4
overlapSize = 12     // ~50 символов / 4
```

Эта стратегия точнее соответствует тому, как LLM обрабатывают текст.

#### 1.3 По предложениям (BY_SENTENCES)

Сохраняет семантические границы, группируя целые предложения.

```kotlin
// Текст разбивается по паттерну: [.!?]+\\s+
// Предложения группируются, пока не превышен chunkSize
```

**Преимущества:** сохраняет целостность мысли
**Недостатки:** размер чанков может сильно варьироваться

### Конфигурация чанков

```kotlin
data class ChunkConfig(
    val strategy: ChunkStrategy = ChunkStrategy.BY_CHARACTERS,
    val chunkSize: Int = 500,
    val overlapSize: Int = 50
)
```

### Структура чанка

```kotlin
data class TextChunk(
    val text: String,        // содержимое чанка
    val chunkIndex: Int,     // порядковый номер (0, 1, 2...)
    val totalChunks: Int,    // общее количество чанков в документе
    val sourceFile: String   // имя исходного файла
)
```

## 2. Векторизация (Embedding Generation)

### Что такое эмбеддинг?

Эмбеддинг — это числовой вектор фиксированной размерности, представляющий семантическое значение текста. Тексты с похожим смыслом имеют близкие векторы.

### Модель nomic-embed-text

| Характеристика | Значение |
|----------------|----------|
| Размерность вектора | 768 |
| Размер модели | ~270 МБ |
| Максимальная длина текста | 8192 токена |

### Процесс генерации

```kotlin
class OllamaEmbeddingService(
    private val ollamaApi: OllamaApi,
    private val model: String = "nomic-embed-text",
    private val batchSize: Int = 10  // батч = 10 текстов
)
```

**Пакетная обработка:**
- Тексты отправляются пакетами по 10 штук
- Это оптимизирует производительность и снижает накладные расходы на сеть

**Пример запроса к Ollama:**
```json
POST /api/embed
{
  "model": "nomic-embed-text",
  "input": ["текст чанка 1", "текст чанка 2", ...]
}
```

**Ответ:**
```json
{
  "embeddings": [
    [0.123, -0.456, 0.789, ...],  // 768 чисел для чанка 1
    [0.234, -0.567, 0.890, ...]   // 768 чисел для чанка 2
  ]
}
```

## 3. Хранение данных

### Структура базы данных SQLite

```
~/.document-indexer/indexer.db
```

#### Таблица indexed_files

| Поле | Тип | Описание |
|------|-----|----------|
| id | INTEGER | Первичный ключ |
| file_name | TEXT | Имя файла |
| file_path | TEXT | Полный путь |
| checksum | TEXT | MD5-хеш содержимого |
| file_size | INTEGER | Размер в байтах |
| chunk_count | INTEGER | Количество чанков |
| indexed_at | INTEGER | Время индексации (timestamp) |
| last_modified | INTEGER | Время изменения файла |

#### Таблица indexed_chunks

| Поле | Тип | Описание |
|------|-----|----------|
| id | INTEGER | Первичный ключ |
| file_id | INTEGER | Ссылка на файл |
| chunk_index | INTEGER | Номер чанка |
| total_chunks | INTEGER | Всего чанков в файле |
| text | TEXT | Текст чанка |
| embedding | BLOB | Сериализованный вектор (768 float) |
| created_at | INTEGER | Время создания |

### Оптимизации

- **MD5-чексумма:** позволяет пропускать неизменённые файлы при повторной индексации
- **Каскадное удаление:** при удалении файла автоматически удаляются все его чанки

## 4. Семантический поиск

### Алгоритм поиска

```
1. Получить поисковый запрос от пользователя
2. Сгенерировать эмбеддинг запроса через Ollama
3. Загрузить все чанки с эмбеддингами из БД
4. Вычислить косинусное сходство между запросом и каждым чанком
5. Отсортировать по убыванию сходства
6. Вернуть Top-K результатов
```

### Косинусное сходство (Cosine Similarity)

Мера сходства двух векторов, не зависящая от их длины:

```kotlin
fun cosineSimilarity(a: List<Float>, b: List<Float>): Float {
    var dotProduct = 0f
    var normA = 0f
    var normB = 0f

    for (i in a.indices) {
        dotProduct += a[i] * b[i]
        normA += a[i] * a[i]
        normB += b[i] * b[i]
    }

    return dotProduct / (sqrt(normA) * sqrt(normB))
}
```

**Диапазон значений:**
- `1.0` — идентичные векторы (полное совпадение смысла)
- `0.0` — ортогональные векторы (нет связи)
- `-1.0` — противоположные векторы (противоположный смысл)

### Результат поиска

```kotlin
data class SearchResult(
    val chunk: IndexedChunk,  // найденный чанк
    val file: IndexedFile,    // файл-источник
    val similarity: Float     // оценка сходства (0.0 - 1.0)
)
```

## 5. Пример полного цикла

### Индексация документа

```
Файл: architecture.md (2500 символов)
           │
           v
┌──────────────────────────────┐
│ TextChunker (BY_CHARACTERS)  │
│ chunkSize=500, overlap=50    │
└──────────────────────────────┘
           │
           v
Чанк 1: [0-500]     "# Архитектура системы..."
Чанк 2: [450-950]   "...включая разбиение на чанки..."
Чанк 3: [900-1400]  "...векторизацию и семантический..."
Чанк 4: [1350-1850] "...поиск. Обзор процесса..."
Чанк 5: [1800-2300] "...документы разбиваются..."
Чанк 6: [2250-2500] "...и сохраняются в БД."
           │
           v
┌──────────────────────────────┐
│ OllamaEmbeddingService       │
│ model=nomic-embed-text       │
│ batchSize=10                 │
└──────────────────────────────┘
           │
           v
Вектор 1: [0.12, -0.34, 0.56, ...] (768 чисел)
Вектор 2: [0.23, -0.45, 0.67, ...]
...
           │
           v
┌──────────────────────────────┐
│ SQLite Database              │
│ ~/.document-indexer/indexer.db│
└──────────────────────────────┘
```

### Поиск по запросу

```
Запрос: "как работает разбиение на чанки?"
           │
           v
┌──────────────────────────────┐
│ Генерация эмбеддинга запроса │
│ [0.15, -0.38, 0.52, ...]     │
└──────────────────────────────┘
           │
           v
┌──────────────────────────────┐
│ Сравнение со всеми чанками   │
│ cosine(query, chunk_i)       │
└──────────────────────────────┘
           │
           v
Чанк 2: similarity = 0.89  ✓ (совпадение по "разбиение на чанки")
Чанк 3: similarity = 0.76
Чанк 1: similarity = 0.71
Чанк 5: similarity = 0.65
Чанк 4: similarity = 0.58
           │
           v
┌──────────────────────────────┐
│ Top-K = 5 результатов        │
│ отсортированных по similarity│
└──────────────────────────────┘
```

## 6. Рекомендации по настройке

### Выбор размера чанка

| Размер | Плюсы | Минусы |
|--------|-------|--------|
| 200-300 | Точный поиск | Много чанков, медленная индексация |
| 500 (по умолчанию) | Баланс точности и производительности | — |
| 1000+ | Быстрая индексация | Менее точный поиск |

### Выбор перекрытия

| Перекрытие | Рекомендация |
|------------|--------------|
| 0% | Не рекомендуется — потеря контекста на границах |
| 10% (50 из 500) | Оптимально для большинства случаев |
| 20%+ | Для документов с длинными предложениями |

### Выбор стратегии

| Тип документов | Рекомендуемая стратегия |
|----------------|-------------------------|
| Технические документы | BY_CHARACTERS |
| Художественные тексты | BY_SENTENCES |
| Смешанные | BY_CHARACTERS |

## 7. Ключевые файлы кода

| Компонент | Путь |
|-----------|------|
| Интерфейс TextChunker | `shared/.../domain/service/TextChunker.kt` |
| Реализация TextChunker | `shared/.../domain/service/TextChunkerImpl.kt` |
| Сервис эмбеддингов | `indexer/.../domain/service/OllamaEmbeddingService.kt` |
| Сервис индексации | `indexer/.../domain/service/DocumentIndexerService.kt` |
| Локальный репозиторий | `indexer/.../data/local/IndexerLocalRepositoryImpl.kt` |
| API Ollama | `indexer/.../data/api/OllamaApiImpl.kt` |
